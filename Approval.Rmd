---
title: "Presidential Approval"
author: "Ed Young"
date:  '`r format(Sys.Date(), "%B %d, %Y")`'
output:
  html_document:
    css: styles.css
    highlight: null
    theme: null
  df_print: kable
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
     echo = FALSE,
     warning = FALSE,
     message = FALSE,
     cache = FALSE
)

library(here)
source(here("R", "load_packages.R"))

# Define the URL and the local file path
url <- "https://www.nytimes.com/newsgraphics/polls/approval/president.csv"
data_dir <- "data"
file_path <- file.path(data_dir, "president.csv")

# Determine whether a download is needed:
# - Either the file doesn't exist...
# - Or the file exists but was last modified before today.
download_needed <- !file.exists(file_path) ||
  as.Date(file.info(file_path)$mtime) < Sys.Date()

if (download_needed) {
  download.file(url, file_path, mode = "wb")
  message("Downloaded a fresh copy of president.csv.")
} else {
  message("The president.csv file is already up-to-date; no download needed.")
}

# Read the CSV file into R for use in your RMarkdown
president <- read.csv(file_path, stringsAsFactors = FALSE)

# Convert end_date to Date format


president <- president %>%
  mutate(
    end_date = as.Date(end_date, format = "%m/%d/%y"),
    created_at = as.Date(created_at, format = "%m/%d/%y")
  ) %>%
  filter(created_at >= end_date | is.na(end_date) | is.na(created_at))

cv_optimal_loess_span <- function(data, 
                                       k = 5,
                                       span_grid = seq(0.2, 0.8, by = 0.05)) {

  if (!all(c("response", "percentage", "end_date") %in% names(data))) {
    stop("Data must contain 'response', 'percentage', and 'end_date' columns.")
  }

  if (!"sample_size" %in% names(data)) {
    stop("Missing column: sample_size")
  }

  if (!"weight" %in% names(data)) {
    data <- data %>% mutate(weight = sample_size)
  }

  data <- data %>%
    mutate(date_num = as.numeric(end_date)) %>%
    drop_na(percentage, date_num, weight)

  # Apply CV separately for each response category
  best_spans <- data %>%
    group_split(response) %>%
    map_df(function(df) {
      res <- unique(df$response)

      cv_errors <- tibble(span = span_grid) %>%
        mutate(cv_error = map_dbl(span, function(span) {
          set.seed(42)
          df_cv <- df %>% mutate(fold = sample(1:k, n(), replace = TRUE))

          fold_errors <- map_dbl(1:k, function(fold_id) {
            train <- df_cv %>% filter(fold != fold_id)
            test  <- df_cv %>% filter(fold == fold_id)

            test <- test %>%
              filter(date_num >= min(train$date_num),
                     date_num <= max(train$date_num))

            if (nrow(train) < 5 || nrow(test) < 1) return(Inf)

            model <- tryCatch({
              loess(percentage ~ date_num, data = train,
                    weights = weight, span = span)
            }, error = function(e) return(NULL))

            if (is.null(model)) return(Inf)

            preds <- predict(model, newdata = test)
            if (all(is.na(preds))) return(Inf)

            mean((test$percentage - preds)^2, na.rm = TRUE)
          })

          mean(fold_errors, na.rm = TRUE)
        }))

      best <- cv_errors %>%
        slice_min(cv_error, with_ties = FALSE)

      tibble(response = res, best_span = best$span)
    })
  
  best_spans <- best_spans %>%
  group_by(response) %>%
  slice_min(best_span, n = 1, with_ties = FALSE) %>%
  ungroup()

  return(best_spans)
}

```

# I am using the New York Times Presidential Approval Polls to look at trends over time.  

##  The first graph is the raw data with LOESS smoothing curves.

```{r raw}

# Reshape the data into long format for easier plotting
president_long <- pivot_longer(president, 
                               cols = c("yes", "no"), 
                               names_to = "response", 
                               values_to = "percentage")
label_points <- president_long %>%
  group_split(response) %>%
  map_df(function(df) {
    latest_date <- max(df$end_date, na.rm = TRUE)
    model <- loess(percentage ~ as.numeric(end_date), data = df, span = 0.5)
    smoothed <- predict(model, newdata = data.frame(end_date = as.numeric(latest_date)))
    
    tibble(
      response = unique(df$response),
      latest_date = latest_date,
      smoothed = smoothed
    )
  })

# Plot

best_span <- cv_optimal_loess_span(president_long)



# Add best span and numeric date to data
plot_data <- president_long %>%
  left_join(best_span, by = "response") %>%
  mutate(date_num = as.numeric(end_date)) %>%
  mutate(weight_var = if ("weight" %in% names(.)) weight else sample_size)

# Create smoothed values manually per response group
smoothed_curves <- plot_data %>%
  group_by(response) %>%
  arrange(date_num) %>%
  nest() %>%
  left_join(best_span, by = "response") %>%
  mutate(
    data = map(data, ~ {
      df <- .
      df %>% mutate(weight_var = if ("weight" %in% names(df)) weight else sample_size)
    }),
    model = map2(data, best_span, function(df, span_val) {
      if (is.na(span_val) || length(span_val) != 1) return(NULL)
      tryCatch(
        loess(percentage ~ date_num, data = df, weights = df$weight_var, span = span_val),
        error = function(e) {
          message("LOESS error: ", e$message)
          return(NULL)
        }
      )
    }),
    smoothed = map2(model, data, function(mod, df) {
      if (is.null(mod)) return(NULL)
      tibble(
        end_date = df$end_date,
        response = df$response[1],
        smoothed = predict(mod, newdata = df)
      )
    })
  ) %>%
  filter(!map_lgl(smoothed, is.null)) %>%
  select(response, smoothed) %>%
  unnest(smoothed)




ggplot(plot_data, aes(x = end_date, y = percentage, color = response)) +
  geom_point(alpha = 0.4, aes(weight = weight_var)) +
  geom_line(data = smoothed_curves, aes(y = smoothed)) +
  labs(title = "Smoothed Support by Response Type",
       y = "Percentage", x = "End Date", color = "Response") +
  theme_minimal()


  
```

##  This second graph uses the same data, but, following the New York Times, I only include the following selected pollsters: Ipsos, American Research Group, Beacon Research/Shaw & Company Research, Gallup, AtlasIntel, Hart Research Associates/Public Opinion Strategies, Quinnipiac University, Emerson College, CNN/SSRS, Cygnal Political, Public Opinion Strategies, Marist College, Marquette Law School, Pew Research Center.  In addition, the data is weighted for recency, sample size and Probability Panel methodology. 

### Weights
<span style="display:block" id="math">
$$
\text{Weight}_i = 0.5 \cdot e^{-\log(2) \cdot \frac{\text{days ago}_i}{14}} 
\;+\; 0.3 \cdot \frac{\log(1 + \text{sample size})}{\max_j \log(1 + \text{sample size})} 
\;+\; 0.2 \cdot \mathbb{1}_{\{\text{methodology} = \text{``Probability Panel''}\}}
$$
</span>

```{r weighted}

# Create a weighting column
# Define reference date as most recent date in the dataset
latest_date <- max(president$end_date, na.rm = TRUE)

# Calculate days since latest poll (for time decay)
president_weight <- president %>%
  filter(pollster %in% c("Ipsos", 
                           "American Research Group", 
                           "Beacon Research/Shaw & Company Research",
                           "Gallup",
                           "AtlasIntel",
                           "Hart Research Associates/Public Opinion Strategies",
                           "Quinnipiac University",
                           "Emerson College",
                           "CNN/SSRS",
                           "Cygnal Political",
                           "Public Opinion Strategies",
                           "Marist College",
                           "Marquette Law School",
                           "Pew Research Center")) %>%
  mutate(
    days_ago = as.numeric(latest_date - end_date),
    
    # Time decay: exponential decay with half-life of 14 days
    time_weight = exp(-log(2) * days_ago / 14),
    
    # Sample size weight: log-scaled and normalized
    size_weight = log1p(sample_size),
    size_weight = size_weight / max(size_weight, na.rm = TRUE),
    
    # Methodology weight: +1 if Probability Sample, else 0
    is_prob_panel = grepl("Probability Panel", methodology, ignore.case = TRUE) &
                    !grepl("Nonprobability Panel", methodology, ignore.case = TRUE),
    method_weight = ifelse(is_prob_panel, 1, 0),
    
    # Final composite weight (can be tuned)
    weight = (0.5 * time_weight) + 
             (0.3 * size_weight) + 
             (0.2 * method_weight)
  )

# Reshape to long format
president_weight_long <- pivot_longer(president_weight, 
                               cols = c("yes", "no"), 
                               names_to = "response", 
                               values_to = "percentage")

# Fit separate loess models for "yes" and "no"

yes_data <- filter(president_weight_long, response == "yes")
best_span <- cv_optimal_loess_span(yes_data)
print(best_span)

loess_yes <- loess(percentage ~ as.numeric(end_date),
                   data = yes_data,
                   weights = yes_data$weight,
                   span = best_span)

pred_yes <- predict(loess_yes, newdata = data.frame(end_date = as.numeric(yes_data$end_date)),
                    se = TRUE)

yes_data <- yes_data %>%
  mutate(
    fit = pred_yes$fit,
    se = pred_yes$se.fit,
    ci_upper = fit + 1.96 * se,
    ci_lower = fit - 1.96 * se
  )

# NO model
no_data <- filter(president_weight_long, response == "no")
best_span <- cv_optimal_loess_span(no_data)
print(best_span)

loess_no <- loess(percentage ~ as.numeric(end_date),
                  data = no_data,
                  weights = no_data$weight,
                  span = )

pred_no <- predict(loess_no, newdata = data.frame(end_date = as.numeric(no_data$end_date)),
                   se = TRUE)

no_data <- no_data %>%
  mutate(
    fit = pred_no$fit,
    se = pred_no$se.fit,
    ci_upper = fit + 1.96 * se,
    ci_lower = fit - 1.96 * se
  )

# Combine for plotting
loess_all <- bind_rows(yes_data, no_data)

# Predict fitted values for plotting
president_weight_long <- president_weight_long %>%
  mutate(smoothed = case_when(
    response == "yes" ~ predict(loess_yes, newdata = data.frame(end_date = as.numeric(end_date))),
    response == "no"  ~ predict(loess_no, newdata = data.frame(end_date = as.numeric(end_date)))
  ))

label_points <- loess_all %>%
  group_by(response) %>%
  filter(end_date == max(end_date, na.rm = TRUE)) %>%
  ungroup()

# Plot with smoothed loess lines

ggplot(loess_all, aes(x = end_date, y = percentage, color = response)) +
  geom_point(alpha = 0.3) +
  geom_line(aes(y = fit), size = 1) +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper, fill = response), 
              alpha = 0.2, color = NA) +
  scale_color_manual(values = c("yes" = "red", "no" = "black"), drop = FALSE) +
  scale_fill_manual(values = c("yes" = "red", "no" = "black"), drop = FALSE) +
  labs(title = "Weighted LOESS Smoothed Polling Trends with 95% Confidence Intervals",
       x = "Poll End Date", y = "Response (%)") +
  geom_text(data = label_points, 
            aes(x = end_date, y = fit, label = paste0("Latest: ", round(fit, 1), "%")),
            hjust = -0.1, vjust = -0.2, size = 3, show.legend = FALSE) +
  scale_color_manual(values = c("yes" = "red", "no" = "black")) +
  scale_fill_manual(values = c("yes" = "red", "no" = "black")) +
  labs(title = "Selected Pollsters Weighted for Recency, Sample Size, and Methodology",
       x = "Poll End Date",
       y = "Response (%)",
       color = "Response",
       fill = "Response") +
  theme_minimal() +
  xlim(min(loess_all$end_date), max(loess_all$end_date) + 10)  # give labels some space
```

# Here are some diagnostics to help think about these different factors

## First is a graph using only the Probability Panels

```{r Probability Diagnostic}
# Filter to only Probability Panel
president_prob <- president %>%
  filter(
    grepl("Probability Panel", methodology, ignore.case = TRUE) & 
    !grepl("Nonprobability Panel", methodology, ignore.case = TRUE)
  )

# Reshape into long format
president_long <- pivot_longer(president_prob, 
                               cols = c("yes", "no"), 
                               names_to = "response", 
                               values_to = "percentage")

label_points <- president_long %>%
  group_split(response) %>%
  map_df(function(df) {
    latest_date <- max(df$end_date, na.rm = TRUE)
    model <- loess(percentage ~ as.numeric(end_date), data = df, span = 0.5)
    smoothed <- predict(model, newdata = data.frame(end_date = as.numeric(latest_date)))
    
    tibble(
      response = unique(df$response),
      latest_date = latest_date,
      smoothed = smoothed
    )
  })

# Plot with trend lines
ggplot(president_long, aes(x = end_date, y = percentage, color = response)) +
  geom_point(alpha = 0.6) +
  geom_smooth(method = "loess", span = 0.5, se = TRUE, linewidth = 1) +
  geom_text(data = label_points,
            aes(x = latest_date, y = smoothed,
                label = paste0("Latest: ", round(smoothed, 1), "%")),
            inherit.aes = FALSE,
            hjust = -0.1, vjust = -0.2, size = 3, show.legend = FALSE) +
  scale_color_manual(values = c("yes" = "red", "no" = "black")) +
  labs(title = "Probability Panel Polls",
       x = "Poll End Date",
       y = "Response (%)",
       color = "Response") +
  theme_minimal() +
  xlim(min(president_long$end_date), max(president_long$end_date) + 10)

```

## This is a graph using only selected pollsters

```{r selected}
# Convert end_date to Date format
president$end_date <- as.Date(president$end_date, format = "%m/%d/%y")

# Reshape the data into long format for easier plotting
president_long <- president %>%
  filter(pollster %in% c("Ipsos", 
                        "American Research Group", 
                        "Beacon Research/Shaw & Company Research",
                        "Gallup",
                        "AtlasIntel",
                        "Hart Research Associates/Public Opinion Strategies",
                        "Quinnipiac University",
                        "Emerson College",
                        "CNN/SSRS",
                        "Cygnal Political",
                        "Public Opinion Strategies",
                        "Marist College",
                        "Marquette Law School",
                        "Pew Research Center")) %>%
  pivot_longer(cols = c("yes", "no"), 
               names_to = "response", 
               values_to = "percentage")

label_points <- president_long %>%
  group_split(response) %>%
  map_df(function(df) {
    latest_date <- max(df$end_date, na.rm = TRUE)
    model <- loess(percentage ~ as.numeric(end_date), data = df, span = 0.5)
    smoothed <- predict(model, newdata = data.frame(end_date = as.numeric(latest_date)))
    
    tibble(
      response = unique(df$response),
      latest_date = latest_date,
      smoothed = smoothed
    )
  })

# Plot
ggplot(president_long, aes(x = end_date, y = percentage, color = response)) +
  geom_point(alpha = 0.6) +  # Semi-transparent points
  geom_smooth(se = TRUE, method = "loess", span = 0.5, linewidth = 1) +  # Trend lines
  geom_text(data = label_points,
            aes(x = latest_date, y = smoothed,
                label = paste0("Latest: ", round(smoothed, 1), "%")),
            inherit.aes = FALSE,
            hjust = -0.1, vjust = -0.2, size = 3, show.legend = FALSE) +
  scale_color_manual(values = c("yes" = "red", "no" = "black")) +
  labs(title = "Selected Pollsters",
       x = "Poll End Date",
       y = "Response (%)",
       color = "Approval") +
  theme_minimal() +
  xlim(min(president_long$end_date), max(president_long$end_date) + 10)
```

## This a graph weighted only by sample size

```{r Sample Size Diagnostic}

president_size <- president %>%
  mutate(
    # Sample size weight: log-scaled and normalized
    size_weight = log1p(sample_size),
    size_weight = size_weight / max(size_weight, na.rm = TRUE),
  )


# Reshape to long format
president_size_long <- pivot_longer(president_size, 
                               cols = c("yes", "no"), 
                               names_to = "response", 
                               values_to = "percentage")

# Fit separate loess models for "yes" and "no"
yes_data <- filter(president_size_long, response == "yes")

loess_yes <- loess(percentage ~ as.numeric(end_date), 
                   data = yes_data, 
                   weights = yes_data$size_weight,
                   span = 0.5)

pred_yes <- predict(loess_yes, newdata = data.frame(end_date = as.numeric(yes_data$end_date)), se = TRUE)

yes_data <- yes_data %>%
  mutate(
    smoothed = pred_yes$fit,
    se = pred_yes$se.fit,
    ci_upper = smoothed + 1.96 * se,
    ci_lower = smoothed - 1.96 * se
  )

no_data <- filter(president_size_long, response == "no")

loess_no <- loess(percentage ~ as.numeric(end_date), 
                  data = no_data, 
                  weights = no_data$size_weight,
                  span = 0.5)

pred_no <- predict(loess_no, newdata = data.frame(end_date = as.numeric(no_data$end_date)), se = TRUE)

no_data <- no_data %>%
  mutate(
    smoothed = pred_no$fit,
    se = pred_no$se.fit,
    ci_upper = smoothed + 1.96 * se,
    ci_lower = smoothed - 1.96 * se
  )


# Predict fitted values for plotting
president_smoothed <- bind_rows(yes_data, no_data)

label_points <- president_smoothed %>%
  group_by(response) %>%
  filter(end_date == max(end_date, na.rm = TRUE)) %>%
  ungroup()

# Plot with smoothed loess lines
ggplot(president_smoothed, aes(x = end_date, y = percentage, color = response)) +
  geom_point(alpha = 0.4) +
  geom_line(aes(y = smoothed), linewidth = 1) +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper, fill = response), alpha = 0.2, color = NA) +
  scale_color_manual(values = c("yes" = "red", "no" = "black"), drop = FALSE) +
  scale_fill_manual(values = c("yes" = "red", "no" = "black"), drop = FALSE) +
  labs(title = "Sample Size",
       x = "Poll End Date",
       y = "Response (%)",
       color = "Response",
       fill = "Response") + 
  geom_text(data = label_points, 
            aes(x = end_date, y = smoothed, label = paste0("Latest: ", round(smoothed, 1), "%")),
            hjust = -0.1, vjust = -0.2, size = 3, show.legend = FALSE) +
  scale_color_manual(values = c("yes" = "red", "no" = "black")) +
  scale_fill_manual(values = c("yes" = "red", "no" = "black")) +
  labs(title = "Weighted for Sample Size",
       x = "Poll End Date",
       y = "Response (%)",
       color = "Response",
       fill = "Response") +
  theme_minimal() +
  xlim(min(president_smoothed$end_date), max(president_smoothed$end_date) + 10)  # give labels some space
```

## Polls weighted only for recency

```{r recency}

# Create a weighting column
# Define reference date as most recent date in the dataset
latest_date <- max(president$end_date, na.rm = TRUE)

# Calculate days since latest poll (for time decay)
president_recency <- president %>%
  mutate(
    days_ago = as.numeric(latest_date - end_date),
    
    # Time decay: exponential decay with half-life of 14 days
    time_weight = exp(-log(2) * days_ago / 14),
    
    # Final composite weight (can be tuned)
    weight = 0.5 * time_weight
  )

# Reshape to long format
president_recency_long <- pivot_longer(president_recency, 
                               cols = c("yes", "no"), 
                               names_to = "response", 
                               values_to = "percentage")

# Fit separate loess models for "yes" and "no"
yes_data <- filter(president_recency_long, response == "yes")

loess_yes <- loess(percentage ~ as.numeric(end_date),
                   data = yes_data,
                   weights = yes_data$weight,
                   span = 0.5)

pred_yes <- predict(loess_yes, newdata = data.frame(end_date = as.numeric(yes_data$end_date)),
                    se = TRUE)

yes_data <- yes_data %>%
  mutate(
    fit = pred_yes$fit,
    se = pred_yes$se.fit,
    ci_upper = fit + 1.96 * se,
    ci_lower = fit - 1.96 * se
  )

# NO model
no_data <- filter(president_recency_long, response == "no")

loess_no <- loess(percentage ~ as.numeric(end_date),
                  data = no_data,
                  weights = no_data$weight,
                  span = 0.5)

pred_no <- predict(loess_no, newdata = data.frame(end_date = as.numeric(no_data$end_date)),
                   se = TRUE)

no_data <- no_data %>%
  mutate(
    fit = pred_no$fit,
    se = pred_no$se.fit,
    ci_upper = fit + 1.96 * se,
    ci_lower = fit - 1.96 * se
  )

# Combine for plotting
loess_all <- bind_rows(yes_data, no_data)

# Predict fitted values for plotting
president_recency_long <- president_recency_long %>%
  mutate(smoothed = case_when(
    response == "yes" ~ predict(loess_yes, newdata = data.frame(end_date = as.numeric(end_date))),
    response == "no"  ~ predict(loess_no, newdata = data.frame(end_date = as.numeric(end_date)))
  ))

label_points <- loess_all %>%
  group_by(response) %>%
  filter(end_date == max(end_date, na.rm = TRUE)) %>%
  ungroup()

# Plot with smoothed loess lines
ggplot(loess_all, aes(x = end_date, y = percentage, color = response)) +
  geom_point(alpha = 0.3) +
  geom_line(aes(y = fit), size = 1) +
  geom_ribbon(aes(ymin = ci_lower, ymax = ci_upper, fill = response), 
              alpha = 0.2, color = NA) +
  scale_color_manual(values = c("yes" = "red", "no" = "black"), drop = FALSE) +
  scale_fill_manual(values = c("yes" = "red", "no" = "black"), drop = FALSE) +
  labs(title = "Weighted for Recency",
       x = "Poll End Date", y = "Response (%)") +
  geom_text(data = label_points, 
            aes(x = end_date, y = fit, label = paste0("Latest: ", round(fit, 1), "%")),
            hjust = -0.1, vjust = -0.2, size = 3, show.legend = FALSE) +
  scale_color_manual(values = c("yes" = "red", "no" = "black")) +
  scale_fill_manual(values = c("yes" = "red", "no" = "black")) +
  labs(title = "Weighted for Recency",
       x = "Poll End Date",
       y = "Response (%)",
       color = "Response",
       fill = "Response") +
  theme_minimal() +
  xlim(min(loess_all$end_date), max(loess_all$end_date) + 10)  # give labels some space
```

##  Plot weight vs. end_date to see how time decay is working:

```{r Time Decau Diagnostic}
ggplot(president_weight, aes(x = end_date, y = weight)) +
  geom_point(alpha = 0.7) +
  labs(title = "Poll Weights Over Time",
       x = "Poll End Date",
       y = "Computed Weight") +
  theme_minimal()
```

##  break down the contributions of time, sample size, and methodology to the final weight

```{r Variable Contribution Diagnostic}
president_weight_long <- president_weight %>%
  select(end_date, time_weight, size_weight, method_weight) %>%
  pivot_longer(cols = -end_date, names_to = "component", values_to = "value")

ggplot(president_weight_long, aes(x = end_date, y = value, color = component)) +
  geom_line(stat = "summary", fun = mean) +
  labs(title = "Average Contribution of Weight Components Over Time",
       x = "Poll End Date", y = "Component Value",
       color = "Component") +
  theme_minimal()
```